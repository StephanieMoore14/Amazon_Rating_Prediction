{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE150A- Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Members\n",
    "* Luis Diaz\n",
    "* Stephanie Moore\n",
    "* Darren Chang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Overview\n",
    "For this assignment, we used a dataset of amazon reviews to look at unigrams and bigrams. The dataset is in JSON format and has information on the number of votes, review ID, user ID, review text, rating, genre ID, and genre. For this assignment we want to find the TF-IDF of the reviews and use it to predict the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Methodology\n",
    "We are going to first read 10,000 reviews from our dataset and clean them from punctuation and capitalization. We'll then get the number of unigrams and bigrams in our corpus and then get unique values. We can then try to predict rating using ridge regression on the 1000 most common unigrams & bigrams. After this, we will adapt both models to tfidf ones and see predict the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict # Dictionaries with default values\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield ast.literal_eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    for l in open(fname):\n",
    "        yield ast.literal_eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the first 10,000 without capitalization or punctuation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = list(parseDataFromFile(\"train_Category.json\"))\n",
    "data = data_[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_votes': 0,\n",
       " 'review_id': 'r99763621',\n",
       " 'user_id': 'u17334941',\n",
       " 'review_text': \"Genuinely enthralling. If Collins or Bernard did invent this out of whole cloth, they deserve a medal for imagination. Lets leave the veracity aside for a moment - always a touchy subject when it comes to real life stories of the occult - and talk about the contents. \\n The Black Alchemist covers a period of two years in which Collins, a magician, and Bernard, a psychic, undertook a series of psychic quests that put them in opposition with the titular Black Alchemist. As entertainment goes, the combination of harrowing discoveries, ancient lore, and going down the pub for a cigarette and a Guinness, trying to make sense of it all while a hen party screams at each other, is a winner. It is simultaneously down to earth and out of this world. \\n It reads fast, both because of the curiousity and because Collins has a very clear writing style. Sometimes its a little clunky or over repetitive and there's a few meetings that get underreported, but I am very much quibbling here. Mostly important, he captures his own and Bernard's sense of wonder, awe and occasionally revulsion enough that I shared them.\",\n",
       " 'rating': 5,\n",
       " 'genreID': 2,\n",
       " 'genre': 'fantasy_paranormal'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data: remove capitalization and punctuation\n",
    "punct = string.punctuation\n",
    "\n",
    "for d in data:\n",
    "    d['review_text'] = d['review_text'].lower() # lowercase string\n",
    "    d['review_text'] = [c for c in d['review_text'] if not ((c in punct) or (c == '\\n'))] # non-punct characters\n",
    "    d['review_text'] = ''.join(d['review_text']) # convert back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genuinely enthralling if collins or bernard did invent this out of whole cloth they deserve a medal for imagination lets leave the veracity aside for a moment  always a touchy subject when it comes to real life stories of the occult  and talk about the contents  the black alchemist covers a period of two years in which collins a magician and bernard a psychic undertook a series of psychic quests that put them in opposition with the titular black alchemist as entertainment goes the combination of harrowing discoveries ancient lore and going down the pub for a cigarette and a guinness trying to make sense of it all while a hen party screams at each other is a winner it is simultaneously down to earth and out of this world  it reads fast both because of the curiousity and because collins has a very clear writing style sometimes its a little clunky or over repetitive and theres a few meetings that get underreported but i am very much quibbling here mostly important he captures his own and bernards sense of wonder awe and occasionally revulsion enough that i shared them'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned review text\n",
    "data[0]['review_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unigrams and bigrams in the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ngrams(corpus, n):\n",
    "    global ngramCount\n",
    "    ngramCount= defaultdict(int)\n",
    "    \n",
    "    global totalNgrams\n",
    "    totalNgrams= 0\n",
    "    for d in corpus:\n",
    "        t = d['review_text']\n",
    "        words = t.split() # tokenizes\n",
    "        Ngrams = list(ngrams(words, n))\n",
    "        for i in Ngrams:\n",
    "            totalNgrams += 1\n",
    "            ngramCount[i] += 1\n",
    "    return ngramCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = gen_ngrams(data, 1)\n",
    "totalUnigrams = totalNgrams\n",
    "unigramCount = ngramCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1511677"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total unigrams found\n",
    "totalUnigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique unigrams\n",
    "len(unigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(73431, ('the',)),\n",
       " (44301, ('and',)),\n",
       " (39577, ('a',)),\n",
       " (36821, ('to',)),\n",
       " (36581, ('i',)),\n",
       " (32552, ('of',)),\n",
       " (21889, ('is',)),\n",
       " (21468, ('in',)),\n",
       " (20110, ('it',)),\n",
       " (19353, ('this',))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 frequent\n",
    "ucounts = [(unigramCount[b], b) for b in unigramCount]\n",
    "ucounts.sort()\n",
    "ucounts.reverse()\n",
    "ucounts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = gen_ngrams(data, 2)\n",
    "totalBigrams = totalNgrams\n",
    "bigramCount = ngramCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501677"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total bigrams found\n",
    "totalBigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521502"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique bigrams\n",
    "len(bigramCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7927, ('of', 'the')),\n",
       " (5850, ('this', 'book')),\n",
       " (5627, ('in', 'the')),\n",
       " (3189, ('and', 'the')),\n",
       " (3183, ('is', 'a'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 frequent\n",
    "bcounts = [(bigramCount[b], b) for b in bigramCount]\n",
    "bcounts.sort()\n",
    "bcounts.reverse()\n",
    "bcounts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**least squares using the 1000 most common unigrams and 1000 most common bigrams. Scored using the MSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def MSE(Y, YH):\n",
    "     return np.square(Y - YH).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugrams = [u[1] for u in ucounts[:1000]]\n",
    "unigramId = dict(zip(ugrams, range(len(ugrams))))\n",
    "unigramSet = set(ugrams)\n",
    "\n",
    "def ug_feature(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    t = datum['review_text']\n",
    "    words = t.strip().split() # tokenizes\n",
    "    ubigrams = list(ngrams(words, 1))\n",
    "    \n",
    "    for u in unigrams:\n",
    "        if not (u in unigramSet): continue\n",
    "        feat[unigramId[u]] += 1\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_X = [ug_feature(d) for d in data]\n",
    "y = [d['rating'] for d in data] #The prediction target should be the ‘rating’ field in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(bg_X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(bg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3453519100001436"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE of unigrams\n",
    "MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrams = [b[1] for b in bcounts[:1000]]\n",
    "bigramId = dict(zip(bgrams, range(len(bgrams))))\n",
    "bigramSet = set(bgrams)\n",
    "\n",
    "def bg_feature(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['review_text']\n",
    "    words = t.strip().split() # tokenizes\n",
    "    bigrams = list(ngrams(words, 2))\n",
    "    \n",
    "    for b in bigrams:\n",
    "        if not (b in bigramSet): continue\n",
    "        feat[bigramId[b]] += 1\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_X = [bg_feature(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(bg_X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(bg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0178804824879226"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE of bigrams\n",
    "MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment above using 1000 most common unigrams and bigrams. Some combination of unigrams and bigrams.Scored using MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(unigramCount[w], w) for w in unigramCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [w[1] for w in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "# unigram feature\n",
    "def ug_feature(datum):\n",
    "    feat = [0]*len(wordSet)\n",
    "    t = datum['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if not (w in wordSet): continue\n",
    "        feat[wordId[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "totalBigrams = totalNgrams\n",
    "bigramCount = ngramCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594788"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 of the most common out of a list of unigrams and bigrams\n",
    "comb = counts + bcounts\n",
    "len(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.sort(key = operator.itemgetter(0), reverse=True) # sort unigrams and bigrams by counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unigrams': 73286, 'bigrams': 521502}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there unigrams and bigrams in comb?\n",
    "l = {'unigrams':0, 'bigrams':0}\n",
    "for e in comb:\n",
    "    if len(e[1]) == 2:\n",
    "        l['bigrams'] += 1\n",
    "    else:\n",
    "        l['unigrams'] += 1\n",
    "l # yes! and its sorted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncounts = comb\n",
    "ngramz = [b[1] for b in ncounts[:1000]]\n",
    "ngramId = dict(zip(ngramz, range(len(ngramz))))\n",
    "ngramSet = set(ngramz)\n",
    "\n",
    "def ng_feature(datum):\n",
    "    feat = [0]*len(ngramSet)\n",
    "    t = datum['review_text']\n",
    "    words = t.strip().split() # tokenizes\n",
    "    bigrams = list(ngrams(words, 2))\n",
    "    unigrams = list(ngrams(words, 1))\n",
    "    \n",
    "    for b in bigrams:\n",
    "        if not (b in ngramSet): continue\n",
    "        feat[ngramId[b]] += 1\n",
    "    \n",
    "    for u in unigrams:\n",
    "        if not (u in ngramSet): continue\n",
    "        feat[ngramId[u]] += 1\n",
    "    feat.append(1) \n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ng_feature(d) for d in data]\n",
    "y = [d['rating'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(bg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5050550974282946"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverse document frequency of the words ‘stories’, ‘magician’, ‘psychic’, ‘writing’, and ‘wonder’.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [d['review_text'] for d in data] # list of documents\n",
    "\n",
    "#instantiate CountVectorizer()\n",
    "cv = CountVectorizer()\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 73250)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stories</th>\n",
       "      <th>magician</th>\n",
       "      <th>psychic</th>\n",
       "      <th>writing</th>\n",
       "      <th>wonder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idf_weights</th>\n",
       "      <td>3.571873</td>\n",
       "      <td>7.074946</td>\n",
       "      <td>6.952344</td>\n",
       "      <td>3.296703</td>\n",
       "      <td>5.062946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stories  magician   psychic   writing    wonder\n",
       "idf_weights  3.571873  7.074946  6.952344  3.296703  5.062946"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = ['stories', 'magician', 'psychic', 'writing', 'wonder']\n",
    "d = {}\n",
    "for w in ws:\n",
    "    d[w] = df_idf.loc[w]\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf scores in the first review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [d['review_text'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count matrix\n",
    "count_vector = cv.transform(docs)\n",
    " \n",
    "# tf-idf scores\n",
    "tf_idf_vector = tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    " \n",
    "#get tfidf vector for first document\n",
    "first_document_vector = tf_idf_vector[0]\n",
    " \n",
    "#print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stories</th>\n",
       "      <th>magician</th>\n",
       "      <th>psychic</th>\n",
       "      <th>writing</th>\n",
       "      <th>wonder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.048453</td>\n",
       "      <td>0.095974</td>\n",
       "      <td>0.188621</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>0.06868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stories  magician   psychic   writing   wonder\n",
       "tfidf  0.048453  0.095974  0.188621  0.044721  0.06868"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for w in ws:\n",
    "    d[w] = df.loc[w]\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adapted td-idf unigram & bigram model to use the tfidf scores for the 1000 most common unigrams & bigrams.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 594591 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract count features and apply TF-IDF normalization \n",
    "docs = [d['review_text'] for d in data]\n",
    "tfidf = TfidfVectorizer(max_features=1000).fit_transform(docs)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['rating'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(fit_intercept=False)\n",
    "clf.fit(tfidf, y)\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0481"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y, np.array([int(p) for p in predictions]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Assessment\n",
    "To assess our models we used Mean Square Error. Models that performed better would have a lower MSE. Under those conditions our best model was a bag of words model trained with the 1000 most common bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What you learned\n",
    "We can see that sometimes it is better to use bigrams over unigrams fro detecting rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Source code and datasets\n",
    "Datasets were used from Julian McaAuley http://cseweb.ucsd.edu/classes/fa19/cse258-a/files/ . The amazon review files are under assignment1.tar.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
